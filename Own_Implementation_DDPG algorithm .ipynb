{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is inspired by the work of Selim Amrouni, Aymeric Moulin and Philippe Mizrahi \n",
    "### who proposed a notebook based implementation of the Algorithm of Zhengyao Jiang, Dixing Xu, Jinjun Liang "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of DDPG algorithm\n",
    "\n",
    "\n",
    "In this notebook we will present our own implementation of the Deep reinforcement learning Algorithm proposed in the paper.We will then use it on stock market data, which contrary to the cryptocurrency market is not open all the time . \n",
    "\n",
    "For precision purpose in the cryptocurrency market we considered 13 crytocurrencies for which we looked at 3 main prices (high,low,open prices). Since the market is continuously open, for each time step t we have open(t)=close(t-1). \n",
    "\n",
    "Here is the outline of what i will be doing trought the notebook:\n",
    "\n",
    "- Preprocessing of the Poloniex cryptocurrency data:\n",
    "   The data X is composed of:\n",
    "     - open(t)/open(t-1)\n",
    "     - high(t)/open(t-1)\n",
    "     - low(t)/open(t-1)\n",
    " \n",
    "- Preprocessing of the S&P500 data :\n",
    "    The final output data X will be a tensor composed of:\n",
    "     - open(t)/open(t-1)\n",
    "     - close(t)/open(t-1)\n",
    "     - high(t)/open(t-1)\n",
    "     - low(t)/open(t-1)\n",
    "     \n",
    "- Implementation of the deep deterministic policy gradient algorithm \n",
    "- possible improvement of the model \n",
    "\n",
    "\n",
    "<u>Remark</u>: \n",
    "The idea of using a ratio of two prices is to normalize the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poloniex data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Libraries and dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for navigation in the folders\n",
    "import os \n",
    "import pathlib\n",
    "\n",
    "# manipulate time\n",
    "from time import strptime \n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# plot \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import PIL\n",
    "import pickle\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/poloniex_data/'\n",
    "directory = os.getcwd()+ data_dir # path to the files of the directory\n",
    "file_tages= os.listdir(directory) # listed all files of the directory\n",
    "\n",
    "#Remove wrong file  \n",
    "for file in file_tages:\n",
    "    if file[0]=='.':\n",
    "        file_tages.remove(file)\n",
    "        \n",
    "stock_names =[file.split('.')[0] for file in file_tages]\n",
    "stocks = [file for file in file_tages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETCBTC.csv 17032\n",
      "GNTETH.csv 7001\n",
      "REPETH.csv 13547\n",
      "ETHBTC.csv 33878\n",
      "DOGEBTC.csv 60915\n",
      "ETHUSDT.csv 33876\n",
      "BTCUSDT.csv 42010\n",
      "XRPBTC.csv 51113\n",
      "DASHBTC.csv 60103\n",
      "REPBTC.csv 13547\n",
      "XMRBTC.csv 55285\n",
      "LTCBTC.csv 61096\n",
      "GNTBTC.csv 7001\n",
      "ETCETH.csv 17031\n"
     ]
    }
   ],
   "source": [
    "# We are interested in one year data history (30min period of trading => 48 periods x 365 days =17000), so the data \n",
    "# that do not exceed that size are removed \n",
    "for s in stocks:\n",
    "    try:\n",
    "        df = pd.read_csv('.'+data_dir+s)\n",
    "        print(s,len(df))\n",
    "    except :\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_stocks = ['ETCBTC','ETHBTC','DOGEBTC','ETHUSDT','BTCUSDT','XRPBTC','DASHBTC',\\\n",
    "              'XMRBTC','LTCBTC','ETCETH']\n",
    "len_list = []\n",
    "for stk in kept_stocks:\n",
    "    data = pd.read_csv('.'+data_dir+stk+'.csv')\n",
    "    len_list.append(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_list=min(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 20.06it/s]\n"
     ]
    }
   ],
   "source": [
    "list_open =list() \n",
    "list_close= list()\n",
    "list_high = list()\n",
    "list_low = list()\n",
    "\n",
    "for s in tqdm(kept_stocks):\n",
    "    data = pd.read_csv('.'+data_dir+s+'.csv').fillna('bfill').copy()\n",
    "    data =data[['open','close','high','low']].tail(min_list)\n",
    "    list_open.append(data.open.values)\n",
    "    list_close.append(data.close.values) \n",
    "    list_high.append(data.high.values)\n",
    "    list_low.append(data.low.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_open_normalizer =np.transpose(np.array(list_open))[:-1]\n",
    "list_open = np.transpose(np.array(list_open))[1:]\n",
    "list_close = np.transpose(np.array(list_close))[1:]\n",
    "list_high = np.transpose(np.array(list_high))[1:]\n",
    "list_low = np.transpose(np.array(list_low))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =np.transpose(np.array([list_open/list_open_normalizer,list_high/list_open_normalizer,list_low/list_open_normalizer]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The shape of our tensor is: $m \\times features \\times data points$\n",
    "    - m = 10 number of stocks\n",
    "    - features = 3 the differents prices \n",
    "    - data points = 17030  number of data points\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./np_data/Cypto_data.npy',X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Market Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/individual_stocks_5yr/'\n",
    "directory = os.getcwd()+ data_dir # path to the files of the directory\n",
    "file_tages= os.listdir(directory) # listed all files of the directory\n",
    "for file in file_tages:\n",
    "    if file[0]=='.':\n",
    "        file_tages.remove(file)\n",
    "        \n",
    "stock_names =[file.split('.')[0] for file in file_tages]\n",
    "stocks = [file for file in file_tages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will considere the stock that have 1256 data points . \n",
    "\n",
    "kept_stocks = list()\n",
    "for stock in stock_names :\n",
    "    try:\n",
    "        df = pd.read_csv('.'+data_dir+stock+'.csv')\n",
    "        if len(df)==1259:\n",
    "            kept_stocks.append(stock+'.csv')\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We considere only some  specific stocks:\n",
    "\n",
    "- 'ALK_data.csv',\n",
    "- 'APC_data.csv',\n",
    "- 'CAG_data.csv',\n",
    "- 'CDNS_data.csv',\n",
    "- 'AMT_data.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALK_data.csv',\n",
       " 'APC_data.csv',\n",
       " 'CAG_data.csv',\n",
       " 'CDNS_data.csv',\n",
       " 'AMT_data.csv']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kept_stocks_sple=[kept_stocks[3], kept_stocks[7], kept_stocks[12], kept_stocks[37], kept_stocks[42]]\n",
    "kept_stocks_sple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_price=list()\n",
    "close_price = list()\n",
    "high_price = list()\n",
    "low_price = list()\n",
    "\n",
    "for s in kept_stocks_sple:\n",
    "    data = pd.read_csv('.'+data_dir+s).fillna('bfill').copy()\n",
    "    data = data[['open','close','high','low']]\n",
    "    open_price.append(data.open.values)\n",
    "    close_price.append(data.close.values)\n",
    "    low_price.append(data.low.values)\n",
    "    high_price.append(data.high.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_close_price = np.array(close_price).T[:-1]\n",
    "array_open_price = np.array(open_price).T[:-1]\n",
    "array_high_price = np.array(high_price).T[:-1]\n",
    "array_low_price= np.array(low_price).T[:-1]\n",
    "array_normalizer_open_price = np.array(open_price).T[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 1258)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.transpose(np.array([array_open_price/array_normalizer_open_price,\\\n",
    "              array_close_price/array_normalizer_open_price,\\\n",
    "              array_high_price/array_normalizer_open_price,\\\n",
    "              array_low_price/array_normalizer_open_price]),axes=(0,2,1))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./np_data/S&P500_data.npy',X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
